from pathlib import Path
from PIL import Image
import streamlit as st

import config
from utils import load_model, infer_uploaded_image, infer_uploaded_video, infer_uploaded_webcam

# setting page layout
st.set_page_config(
    page_title="Interactive Interface for YOLOv8",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
    )

# main page heading
st.title("Interactive Interface for YOLOv8")

# sidebar
st.sidebar.header("DL Model Config")

# model options
task_type = st.sidebar.selectbox(
    "Select Task",
    ["Detection"]
)

model_type = None
if task_type == "Detection":
    model_type = st.sidebar.selectbox(
        "Select Model",
        config.DETECTION_MODEL_LIST
    )
else:
    st.error("Currently only 'Detection' function is implemented")

confidence = float(st.sidebar.slider(
    "Select Model Confidence", 30, 100, 50)) / 100

model_path = ""
if model_type:
    model_path = Path(config.DETECTION_MODEL_DIR, str(model_type))
else:
    st.error("Please Select Model in Sidebar")

# load pretrained DL model
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"Unable to load model. Please check the specified path: {model_path}")

# image/video options
st.sidebar.header("Image/Video Config")
source_selectbox = st.sidebar.selectbox(
    "Select Source",
    config.SOURCES_LIST
)

source_img = None
if source_selectbox == config.SOURCES_LIST[0]: # Image
    infer_uploaded_image(confidence, model)
elif source_selectbox == config.SOURCES_LIST[1]: # Video
    infer_uploaded_video(confidence, model)
elif source_selectbox == config.SOURCES_LIST[2]: # Webcam
    infer_uploaded_webcam(confidence, model)
else:
    st.error("Currently only 'Image' and 'Video' source are implemented")
    
# import streamlit as st
# import cv2
# from ultralytics import YOLO
# import numpy as np
# from PIL import Image
# from utils import load_model, infer_uploaded_image, infer_uploaded_video, infer_uploaded_webcam
# # from ultralytics import solutions

# # Pass a model as an argument
# # solutions.inference(model="./custom_train/yolov8n_rock_paper_scissors.pt")

# # í˜ì´ì§€ ì„¤ì •
# st.set_page_config(page_title="YOLO Model Demo", layout="centered")

# # í˜ì´ì§€ ì œëª© ë° ì„¤ëª…
# st.title("ğŸ¤¸â€â™€ï¸YOLOv8")
# st.title("RockâœŠ, ScissorsâœŒ, PaperğŸ– Detection")
# st.write("""
# YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°€ìœ„, ë°”ìœ„, ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
# ì´ ëª¨ë¸ì€ Roboflowë¥¼ í†µí•´ í•™ìŠµëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ê±°ì³¤ìŠµë‹ˆë‹¤:
# - ë°ì´í„° ìˆ˜ì§‘ ë° ë¼ë²¨ë§
# - ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
# - ì›¹ìº ì„ í†µí•œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€
# """)

# # ìˆ˜í‰ìœ¼ë¡œ ì´ë¯¸ì§€ ì •ë ¬
# col1, col2 = st.columns(2)

# # ê° ì»¬ëŸ¼ì— ì´ë¯¸ì§€ ì¶”ê°€
# with col1:
#     st.image("https://github.com/user-attachments/assets/cbc639f2-7055-419e-a94e-6e1fbe143b61", 
#              caption="Rock, Paper, Scissors Dataset", use_column_width=True)

# with col2:
#     st.image("https://github.com/user-attachments/assets/3840f1b6-06ce-401b-b242-1dc0e1dbf891", 
#              caption="YOLOv8 Model", use_column_width=True)

# # ëª¨ë¸ ì„¤ëª… ì¶”ê°€
# st.write("""
# ìœ„ì˜ ì´ë¯¸ì§€ëŠ” í•™ìŠµëœ ë°ì´í„°ì…‹ê³¼ YOLOv8 ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.
# ì‹¤ì‹œê°„ ì›¹ìº ì—ì„œ ê°€ìœ„âœŒ, ë°”ìœ„âœŠ, ë³´ğŸ– ì¤‘ í•˜ë‚˜ë¥¼ ë‚´ë©´
# yolov8 ëª¨ë¸ì„ í†µí•´ ë¶„ë¥˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ !âœ¨
# """)

# # ì›¹ìº  ì„ íƒ ë° ì„¤ì •
# st.header("ì›¹ìº ì„ í†µí•´ ì‹¤ì‹œê°„ ë¶„ë¥˜í•˜ê¸°")
# camera_index = st.sidebar.selectbox("Select Camera Index", [0, 1, 2])

# # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
# model = YOLO('./custom_train/yolov8n_rock_paper_scissors.pt')  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ

# # ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„ ì¶œë ¥
# st.sidebar.text("Model Classes:")
# st.sidebar.write(model.names)

# # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¶„ë¥˜ ì„¹ì…˜
# st.sidebar.header("Image Upload for Classification")
# uploaded_file = st.sidebar.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])

# if uploaded_file is not None:
#     # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ PILë¡œ ì—´ê¸°
#     image = Image.open(uploaded_file)

#     # ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
#     frame = np.array(image)
#     frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

#     # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ
#     st.image(image, caption="Uploaded Image", use_column_width=True)

#     # ê°ì²´ íƒì§€ (Rock, Paper, Scissors í´ë˜ìŠ¤ íƒì§€)
#     results = model.predict(frame, classes=[0, 1, 2], conf=0.4, imgsz=640)

#     # íƒì§€ëœ ê²°ê³¼ ì‹œê°í™”
#     annotated_frame = results[0].plot()

#     # BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (OpenCVëŠ” BGR í˜•ì‹ì´ë¯€ë¡œ, RGB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í•„ìš”)
#     annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

#     # Streamlitì„ í†µí•´ íƒì§€ëœ ì´ë¯¸ì§€ í‘œì‹œ
#     st.image(annotated_frame, caption="Detected Image", use_column_width=True)

#     # ê°ì§€ëœ ê°ì²´ ëª©ë¡ í‘œì‹œ
#     st.subheader("Detected Objects")
#     if len(results[0].boxes) > 0:
#         for box in results[0].boxes:
#             cls = int(box.cls[0])
#             label = model.names[cls]
#             confidence = box.conf[0]
#             st.write(f"Detected {label} with {confidence:.2f} confidence.")
#     else:
#         st.write("No objects detected.")

# # ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°
# st.header("Real-Time Classification with Webcam")

# # ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ë° ì¤‘ì§€ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” ë³€ìˆ˜
# if "streaming" not in st.session_state:
#     st.session_state.streaming = False

# # ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ë²„íŠ¼
# start_button = st.button("Start Webcam")
# if start_button:
#     st.session_state.streaming = True

# # ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ë²„íŠ¼
# stop_button = st.button("Stop Webcam")
# if stop_button:
#     st.session_state.streaming = False

# # ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœì— ë”°ë¥¸ ì²˜ë¦¬
# if st.session_state.streaming:
#     confidence = 0.25
#     infer_uploaded_webcam(confidence, model)

# #     stframe = st.empty()  # Streamlitì—ì„œ ì‚¬ìš©í•  ë¹ˆ ì´ë¯¸ì§€ í”„ë ˆì„ ì„¤ì •

# #     # while st.session_state.streaming:
# #     # st.camera_input()ì„ ì‚¬ìš©í•˜ì—¬ ì›¹ìº ì—ì„œ í”„ë ˆì„ ìº¡ì²˜
# #     img_file_buffer = st.camera_input("Capture")

# #     if img_file_buffer is not None:
# #         # ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
# #         bytes_data = img_file_buffer.getvalue()
# #         frame = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
# #         # frame = img_file_buffer.getvalue()
# #         # frame = cv2.imdecode(np.frombuffer(frame, np.uint8), cv2.IMREAD_COLOR)
# #         # frame = np.array(Image.open(img_file_buffer))
# #         # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

# #         # ê°ì²´ íƒì§€ (Rock, Paper, Scissors í´ë˜ìŠ¤ íƒì§€)
# #         results = model.predict(frame, classes=[0, 1, 2], conf=0.4, imgsz=640)

# #         # íƒì§€ëœ ê²°ê³¼ ì‹œê°í™”
# #         annotated_frame = results[0].plot()

# #         # BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜ (OpenCVëŠ” BGR í˜•ì‹ì´ë¯€ë¡œ, RGB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ í•„ìš”)
# #         annotated_frame = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)

# #         # Streamlitì„ í†µí•´ ì´ë¯¸ì§€ í‘œì‹œ
# #         stframe.image(annotated_frame, channels="RGB")

# #     st.write("Webcam streaming stopped.")


